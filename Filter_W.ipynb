{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17803d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import os as os\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from filter.RaymondFilters import RaymondFilter\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "from plot_tools import *\n",
    "\n",
    "# Local import \n",
    "\n",
    "from spectra.py_spectra import *\n",
    "\n",
    "# High Pass values for various values of dx - because of high pass, we want the lowpass filter cutoff to have\n",
    "# a large (R~0.9) value\n",
    "\n",
    "npass = 6\n",
    "\n",
    "dx    = 8\n",
    "\n",
    "klevels = [25]\n",
    "\n",
    "filtered_W_name = \"W_%2.2i\" % dx\n",
    "\n",
    "# Helper functions......\n",
    "\n",
    "def add_fhour(ds):\n",
    "    \n",
    "    filename = ds.encoding[\"source\"].split(\"_\")\n",
    "    \n",
    "    init_time = int(filename[-2])\n",
    "    fhour     = int(filename[-1][-5:-3])\n",
    "        \n",
    "    ds.coords['fhour'] = fhour\n",
    "    ds.coords['init_time'] = init_time\n",
    "    \n",
    "    return ds\n",
    "    \n",
    "\n",
    "def read_mfdataset_list(data_dir, pattern):\n",
    "    \"\"\"\n",
    "    Use xarray.open_mfdataset to read multiple netcdf files from a list.\n",
    "    \"\"\"\n",
    "    filelist = os.path.join(data_dir,pattern)\n",
    "    return xr.open_mfdataset(filelist, preprocess=add_fhour, combine='nested', concat_dim=['fhour'],parallel=True)\n",
    "\n",
    "def save_mfdataset_list(ds, dir, gridType=None):\n",
    "    \"\"\"\n",
    "    Use xarray.save_mfdataset to save multiple netcdf files from a list, using the original file strings as a pattern\n",
    "    \"\"\"\n",
    "\n",
    "    # Use new pathlib for Python > 3.5\n",
    "    Path(dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for n, hour in enumerate(ds.fhour):\n",
    "        fcstHour  = ds.isel(fhour=n).fhour.values\n",
    "        fcstStart = ds.isel(fhour=n).fcstStart\n",
    "        date      = ds.isel(fhour=n).date      \n",
    "        \n",
    "        if gridType == None:\n",
    "            gridType = ds.isel(fhour=n).attrs['gridType']\n",
    "            \n",
    "        outfilename = os.path.join(dir, '%s_%08d%02d_F%02d.nc' % (gridType, date, fcstStart, fcstHour))\n",
    "        \n",
    "        ds.isel(fhour=n).to_netcdf(outfilename, mode='w')  \n",
    "        print(f'Successfully wrote new data to file:: {outfilename}','\\n')\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e3ceb360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open data sets\n",
    "\n",
    "def filter_ds(dir, output_dir, suffix, dx = 10, npass = 6, writeout=False):\n",
    "    \n",
    "    new_dir = \"%s_%s\" % (output_dir, suffix)\n",
    "    \n",
    "    ds  = read_mfdataset_list(dir , \"econus_*.nc\")\n",
    "    \n",
    "    print(ds['W'])\n",
    "\n",
    "    # Set up cartopy stuff here, so the plot routine is already set to use it.\n",
    "\n",
    "    fig, axes = init_cartopy_plot(ncols=2, nrows=1, figsize=(20,10))\n",
    "\n",
    "    # Plot the initial data\n",
    "\n",
    "    cb_info = plot_w_from_xarray(ds, fhour=4, title='UNFILTERED', ax = axes[0])\n",
    "\n",
    "    # Convert to numpy arrays, fill in zeros\n",
    "\n",
    "    w = np.nan_to_num(ds.W.values).astype('float64')\n",
    "\n",
    "    nhour, nz, ny, nx = w.shape\n",
    "    \n",
    "    w_filtered = np.zeros_like(w)\n",
    "\n",
    "    for n in np.arange(nhour):\n",
    "        \n",
    "        print(\"File %d being processed\" % n)\n",
    "\n",
    "        w_filtered[n] = RaymondFilter(w[n], dx, klevels=klevels, order=6, npass = npass, fortran = False, highpass=True)\n",
    "    \n",
    "    ds['W'] = xr.DataArray(w_filtered, dims = ['fhour','nz','ny','nx'])\n",
    "    \n",
    "    print(ds['W'])\n",
    "\n",
    "    # Plot the Filtered data\n",
    "\n",
    "    cb_info = plot_w_from_xarray(ds, fhour=4, title='FILTERED', ax = axes[1])\n",
    "\n",
    "    if writeout:\n",
    "        save_mfdataset_list(ds, new_dir, gridType='filtered')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "257dcca7-e2e3-4719-a035-23f975127322",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_config =  {\n",
    "              \"filtered_filename\": \"\",\n",
    "              \"filter_dx\":          12,\n",
    "              \"filter_npass\":       1,\n",
    "              \"input_dir\":   \"/work/larissa.reames\",\n",
    "              \"output_dir\":  \"/work/wicker/CAM_case_studies\",\n",
    "              \"cases\": {\n",
    "                        \"2020030212\": [\"ctrl\"],\n",
    "                        #\"2020030212\": [\"hrrr\", \"ctrl\", \"nord3\", \"nam\"],\n",
    "                        # \"2021052612\": [\"hrrr\", \"ctrl\", \"nord3\"],\n",
    "                       },\n",
    "               \"zoom\": {\n",
    "                        \"2019071918\": [44.0, 49.0,  -92.0, -87.0, 5],\n",
    "                        \"2020081006\": [39.0, 44.0,  -92.0, -86.0, 5],\n",
    "                        \"2020030212\": [34.0, 39.5,  -92.0, -85.0, 2],\n",
    "                        \"2021090100\": [35.5, 43.0,  -80.0, -73.0, 5],\n",
    "                        \"2020050300\": [35.0, 40.0,  -92.0, -85.0, 5],\n",
    "                        \"2020070700\": [42.0, 46.0, -101.0, -96.0, 5],\n",
    "                        \"2021052612\": [33.5, 43.0, -102.5, -97.0, 5],\n",
    "                        # \"2021052612\": [37.0, 40.5, -100., -97.5, 5]\n",
    "                        }\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a654f2d1-78a3-4c0c-a669-5ef478439a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====> Begin processing runs\n",
      "\n",
      "-------> Parameter Filter SCALE: 12 \n",
      "\n",
      "-------> Parameter        NPASS: 1 \n",
      "\n",
      "-------> Parameter FILTERED FILE DIRECTORY: W_12 \n",
      "\n",
      "\n",
      "----> Processing run: ctrl for day:  2020030212 \n",
      "\n",
      "<xarray.DataArray 'W' (fhour: 6, nz: 45, ny: 959, nx: 1128)>\n",
      "dask.array<concatenate, shape=(6, 45, 959, 1128), dtype=float32, chunksize=(1, 45, 959, 1128), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "    pres       (nz) int64 dask.array<chunksize=(45,), meta=np.ndarray>\n",
      "    lons       (ny, nx) float32 dask.array<chunksize=(959, 1128), meta=np.ndarray>\n",
      "    lats       (ny, nx) float32 dask.array<chunksize=(959, 1128), meta=np.ndarray>\n",
      "  * fhour      (fhour) int64 12 13 14 15 16 17\n",
      "    init_time  int64 202003021200\n",
      "Dimensions without coordinates: nz, ny, nx\n",
      "\n",
      "Plot Lat Min: 22.9  Lat Max:  51.6  \n",
      "\n",
      "Plot Lon Min: -108.2  Lon Max:  -62.4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/louis.wicker/miniconda3/envs/main/lib/python3.9/site-packages/cartopy/mpl/geoaxes.py:1597: UserWarning: The input coordinates to pcolormesh are interpreted as cell centers, but are not monotonically increasing or decreasing. This may lead to incorrectly calculated cell edges, in which case, please supply explicit cell edges to pcolormesh.\n",
      "  X, Y, C, shading = self._pcolorargs('pcolormesh', *args,\n"
     ]
    }
   ],
   "source": [
    "# Input data sets....\n",
    "\n",
    "#from input_default import input_single as input_config\n",
    "\n",
    "input_dir  = input_config[\"input_dir\"]\n",
    "output_dir = input_config[\"output_dir\"]\n",
    "\n",
    "filtered_filename = input_config[\"filtered_filename\"]\n",
    "filter_dx         = input_config[\"filter_dx\"]\n",
    "filter_npass      = input_config[\"filter_npass\"]\n",
    "\n",
    "if len(filtered_filename) == 0:\n",
    "    filtered_filename = \"W_%2.2i\" % filter_dx\n",
    "    \n",
    "#------------------------------------------------------------------------------------\n",
    "# cut and past from below here\n",
    "#\n",
    "\n",
    "print(\"\\n====> Begin processing runs\\n\")\n",
    "\n",
    "print(\"-------> Parameter Filter SCALE: %d \\n\" % filter_dx)\n",
    "print(\"-------> Parameter        NPASS: %d \\n\" % filter_npass)\n",
    "print(\"-------> Parameter FILTERED FILE DIRECTORY: %s \\n\" % filtered_filename)\n",
    "\n",
    "for day in input_config[\"cases\"]:\n",
    "    for run in input_config[\"cases\"][day]:\n",
    "        \n",
    "        print(\"\\n----> Processing run: %s for day:  %s \\n\" % (run,day))\n",
    "        run_dir = str(os.path.join(input_dir, day, run))\n",
    "        out_dir = str(os.path.join(output_dir, day, run))\n",
    "        filter_ds(run_dir, out_dir, filtered_filename, dx=filter_dx, npass=filter_npass, writeout=False)\n",
    "        \n",
    "print(\"\\n====> Ended processing runs\\n\")\n",
    "\n",
    "del(input_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6f82e7a1-ed20-4e0b-a353-5e042c83495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    json.dump(input_spec, outfile)\n",
    "    \n",
    "import yaml\n",
    "with open(\"sample.yaml\", \"w\") as outfile:\n",
    "    yaml.dump(input_spec, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278ac359-1257-4b7e-97a5-c8cb257c9660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8fd7c043-44a9-4670-ab44-9466996920fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cases': {'2019071918': ['hrrr', 'ctrl', 'nord3'], '2020081006': ['hrrr', 'ctrl', 'nord3']}, 'input_dir': '/Users/Louis.Wicker/CAM_Case_Studies', 'output_dir': '/Users/Louis.Wicker/CAM_Case_Studies'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"sample.yaml\", \"r\") as outfile:\n",
    "    d = yaml.load(outfile, Loader=yaml.FullLoader)\n",
    "    \n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b8ac4b26-0fe7-4c2f-80f1-6b48a428c127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Parse the first YAML document in a stream\n",
       "and produce the corresponding Python object.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/mypip/lib/python3.9/site-packages/yaml/__init__.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yaml.load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "32eeceb7-b4cf-40e2-8790-fe591c2f1d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "f = \"\"\n",
    "print(len(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e4d82cc-c8f1-469f-be44-6962d099684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import dsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3239cd60-c8ac-4a20-b1a2-2d064475bb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package scipy.sparse.linalg.dsolve in scipy.sparse.linalg:\n",
      "\n",
      "NAME\n",
      "    scipy.sparse.linalg.dsolve\n",
      "\n",
      "DESCRIPTION\n",
      "    Linear Solvers\n",
      "    ==============\n",
      "    \n",
      "    The default solver is SuperLU (included in the scipy distribution),\n",
      "    which can solve real or complex linear systems in both single and\n",
      "    double precisions.  It is automatically replaced by UMFPACK, if\n",
      "    available.  Note that UMFPACK works in double precision only, so\n",
      "    switch it off by::\n",
      "    \n",
      "        >>> use_solver(useUmfpack=False)\n",
      "    \n",
      "    to solve in the single precision. See also use_solver documentation.\n",
      "    \n",
      "    Example session::\n",
      "    \n",
      "        >>> from scipy.sparse import csc_matrix, spdiags\n",
      "        >>> from numpy import array\n",
      "        >>> from scipy.sparse.linalg import spsolve, use_solver\n",
      "        >>>\n",
      "        >>> print(\"Inverting a sparse linear system:\")\n",
      "        >>> print(\"The sparse matrix (constructed from diagonals):\")\n",
      "        >>> a = spdiags([[1, 2, 3, 4, 5], [6, 5, 8, 9, 10]], [0, 1], 5, 5)\n",
      "        >>> b = array([1, 2, 3, 4, 5])\n",
      "        >>> print(\"Solve: single precision complex:\")\n",
      "        >>> use_solver( useUmfpack = False )\n",
      "        >>> a = a.astype('F')\n",
      "        >>> x = spsolve(a, b)\n",
      "        >>> print(x)\n",
      "        >>> print(\"Error: \", a*x-b)\n",
      "        >>>\n",
      "        >>> print(\"Solve: double precision complex:\")\n",
      "        >>> use_solver( useUmfpack = True )\n",
      "        >>> a = a.astype('D')\n",
      "        >>> x = spsolve(a, b)\n",
      "        >>> print(x)\n",
      "        >>> print(\"Error: \", a*x-b)\n",
      "        >>>\n",
      "        >>> print(\"Solve: double precision:\")\n",
      "        >>> a = a.astype('d')\n",
      "        >>> x = spsolve(a, b)\n",
      "        >>> print(x)\n",
      "        >>> print(\"Error: \", a*x-b)\n",
      "        >>>\n",
      "        >>> print(\"Solve: single precision:\")\n",
      "        >>> use_solver( useUmfpack = False )\n",
      "        >>> a = a.astype('f')\n",
      "        >>> x = spsolve(a, b.astype('f'))\n",
      "        >>> print(x)\n",
      "        >>> print(\"Error: \", a*x-b)\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _add_newdocs\n",
      "    _superlu\n",
      "    linsolve\n",
      "    setup\n",
      "    tests (package)\n",
      "\n",
      "CLASSES\n",
      "    builtins.UserWarning(builtins.Warning)\n",
      "        scipy.sparse.linalg.dsolve.linsolve.MatrixRankWarning\n",
      "    builtins.object\n",
      "        builtins.SuperLU\n",
      "    \n",
      "    class MatrixRankWarning(builtins.UserWarning)\n",
      "     |  Method resolution order:\n",
      "     |      MatrixRankWarning\n",
      "     |      builtins.UserWarning\n",
      "     |      builtins.Warning\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.UserWarning:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.UserWarning:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class SuperLU(object)\n",
      "     |  LU factorization of a sparse matrix.\n",
      "     |  \n",
      "     |  Factorization is represented as::\n",
      "     |  \n",
      "     |      Pr * A * Pc = L * U\n",
      "     |  \n",
      "     |  To construct these `SuperLU` objects, call the `splu` and `spilu`\n",
      "     |  functions.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  shape\n",
      "     |  nnz\n",
      "     |  perm_c\n",
      "     |  perm_r\n",
      "     |  L\n",
      "     |  U\n",
      "     |  \n",
      "     |  Methods\n",
      "     |  -------\n",
      "     |  solve\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  \n",
      "     |  .. versionadded:: 0.14.0\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  The LU decomposition can be used to solve matrix equations. Consider:\n",
      "     |  \n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from scipy.sparse import csc_matrix, linalg as sla\n",
      "     |  >>> A = csc_matrix([[1,2,0,4],[1,0,0,1],[1,0,2,1],[2,2,1,0.]])\n",
      "     |  \n",
      "     |  This can be solved for a given right-hand side:\n",
      "     |  \n",
      "     |  >>> lu = sla.splu(A)\n",
      "     |  >>> b = np.array([1, 2, 3, 4])\n",
      "     |  >>> x = lu.solve(b)\n",
      "     |  >>> A.dot(x)\n",
      "     |  array([ 1.,  2.,  3.,  4.])\n",
      "     |  \n",
      "     |  The ``lu`` object also contains an explicit representation of the\n",
      "     |  decomposition. The permutations are represented as mappings of\n",
      "     |  indices:\n",
      "     |  \n",
      "     |  >>> lu.perm_r\n",
      "     |  array([0, 2, 1, 3], dtype=int32)\n",
      "     |  >>> lu.perm_c\n",
      "     |  array([2, 0, 1, 3], dtype=int32)\n",
      "     |  \n",
      "     |  The L and U factors are sparse matrices in CSC format:\n",
      "     |  \n",
      "     |  >>> lu.L.A\n",
      "     |  array([[ 1. ,  0. ,  0. ,  0. ],\n",
      "     |         [ 0. ,  1. ,  0. ,  0. ],\n",
      "     |         [ 0. ,  0. ,  1. ,  0. ],\n",
      "     |         [ 1. ,  0.5,  0.5,  1. ]])\n",
      "     |  >>> lu.U.A\n",
      "     |  array([[ 2.,  0.,  1.,  4.],\n",
      "     |         [ 0.,  2.,  1.,  1.],\n",
      "     |         [ 0.,  0.,  1.,  1.],\n",
      "     |         [ 0.,  0.,  0., -5.]])\n",
      "     |  \n",
      "     |  The permutation matrices can be constructed:\n",
      "     |  \n",
      "     |  >>> Pr = csc_matrix((np.ones(4), (lu.perm_r, np.arange(4))))\n",
      "     |  >>> Pc = csc_matrix((np.ones(4), (np.arange(4), lu.perm_c)))\n",
      "     |  \n",
      "     |  We can reassemble the original matrix:\n",
      "     |  \n",
      "     |  >>> (Pr.T * (lu.L * lu.U) * Pc.T).A\n",
      "     |  array([[ 1.,  2.,  0.,  4.],\n",
      "     |         [ 1.,  0.,  0.,  1.],\n",
      "     |         [ 1.,  0.,  2.,  1.],\n",
      "     |         [ 2.,  2.,  1.,  0.]])\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(rhs[, trans])\n",
      "     |      \n",
      "     |      Solves linear system of equations with one or several right-hand sides.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      rhs : ndarray, shape (n,) or (n, k)\n",
      "     |          Right hand side(s) of equation\n",
      "     |      trans : {'N', 'T', 'H'}, optional\n",
      "     |          Type of system to solve::\n",
      "     |      \n",
      "     |              'N':   A   * x == rhs  (default)\n",
      "     |              'T':   A^T * x == rhs\n",
      "     |              'H':   A^H * x == rhs\n",
      "     |      \n",
      "     |          i.e., normal, transposed, and hermitian conjugate.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      x : ndarray, shape ``rhs.shape``\n",
      "     |          Solution vector(s)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  L\n",
      "     |      Lower triangular factor with unit diagonal as a\n",
      "     |      `scipy.sparse.csc_matrix`.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.14.0\n",
      "     |  \n",
      "     |  U\n",
      "     |      Upper triangular factor as a `scipy.sparse.csc_matrix`.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.14.0\n",
      "     |  \n",
      "     |  nnz\n",
      "     |      Number of nonzero elements in the matrix.\n",
      "     |  \n",
      "     |  perm_c\n",
      "     |      Permutation Pc represented as an array of indices.\n",
      "     |      \n",
      "     |      The column permutation matrix can be reconstructed via:\n",
      "     |      \n",
      "     |      >>> Pc = np.zeros((n, n))\n",
      "     |      >>> Pc[np.arange(n), perm_c] = 1\n",
      "     |  \n",
      "     |  perm_r\n",
      "     |      Permutation Pr represented as an array of indices.\n",
      "     |      \n",
      "     |      The row permutation matrix can be reconstructed via:\n",
      "     |      \n",
      "     |      >>> Pr = np.zeros((n, n))\n",
      "     |      >>> Pr[perm_r, np.arange(n)] = 1\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Shape of the original matrix as a tuple of ints.\n",
      "\n",
      "FUNCTIONS\n",
      "    factorized(A)\n",
      "        Return a function for solving a sparse linear system, with A pre-factorized.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : (N, N) array_like\n",
      "            Input.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        solve : callable\n",
      "            To solve the linear system of equations given in `A`, the `solve`\n",
      "            callable should be passed an ndarray of shape (N,).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse.linalg import factorized\n",
      "        >>> A = np.array([[ 3. ,  2. , -1. ],\n",
      "        ...               [ 2. , -2. ,  4. ],\n",
      "        ...               [-1. ,  0.5, -1. ]])\n",
      "        >>> solve = factorized(A) # Makes LU decomposition.\n",
      "        >>> rhs1 = np.array([1, -2, 0])\n",
      "        >>> solve(rhs1) # Uses the LU factors.\n",
      "        array([ 1., -2., -2.])\n",
      "    \n",
      "    spilu(A, drop_tol=None, fill_factor=None, drop_rule=None, permc_spec=None, diag_pivot_thresh=None, relax=None, panel_size=None, options=None)\n",
      "        Compute an incomplete LU decomposition for a sparse, square matrix.\n",
      "        \n",
      "        The resulting object is an approximation to the inverse of `A`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : (N, N) array_like\n",
      "            Sparse matrix to factorize\n",
      "        drop_tol : float, optional\n",
      "            Drop tolerance (0 <= tol <= 1) for an incomplete LU decomposition.\n",
      "            (default: 1e-4)\n",
      "        fill_factor : float, optional\n",
      "            Specifies the fill ratio upper bound (>= 1.0) for ILU. (default: 10)\n",
      "        drop_rule : str, optional\n",
      "            Comma-separated string of drop rules to use.\n",
      "            Available rules: ``basic``, ``prows``, ``column``, ``area``,\n",
      "            ``secondary``, ``dynamic``, ``interp``. (Default: ``basic,area``)\n",
      "        \n",
      "            See SuperLU documentation for details.\n",
      "        \n",
      "        Remaining other options\n",
      "            Same as for `splu`\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        invA_approx : scipy.sparse.linalg.SuperLU\n",
      "            Object, which has a ``solve`` method.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        splu : complete LU decomposition\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        To improve the better approximation to the inverse, you may need to\n",
      "        increase `fill_factor` AND decrease `drop_tol`.\n",
      "        \n",
      "        This function uses the SuperLU library.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import spilu\n",
      "        >>> A = csc_matrix([[1., 0., 0.], [5., 0., 2.], [0., -1., 0.]], dtype=float)\n",
      "        >>> B = spilu(A)\n",
      "        >>> x = np.array([1., 2., 3.], dtype=float)\n",
      "        >>> B.solve(x)\n",
      "        array([ 1. , -3. , -1.5])\n",
      "        >>> A.dot(B.solve(x))\n",
      "        array([ 1.,  2.,  3.])\n",
      "        >>> B.solve(A.dot(x))\n",
      "        array([ 1.,  2.,  3.])\n",
      "    \n",
      "    splu(A, permc_spec=None, diag_pivot_thresh=None, relax=None, panel_size=None, options={})\n",
      "        Compute the LU decomposition of a sparse, square matrix.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : sparse matrix\n",
      "            Sparse matrix to factorize. Should be in CSR or CSC format.\n",
      "        permc_spec : str, optional\n",
      "            How to permute the columns of the matrix for sparsity preservation.\n",
      "            (default: 'COLAMD')\n",
      "        \n",
      "            - ``NATURAL``: natural ordering.\n",
      "            - ``MMD_ATA``: minimum degree ordering on the structure of A^T A.\n",
      "            - ``MMD_AT_PLUS_A``: minimum degree ordering on the structure of A^T+A.\n",
      "            - ``COLAMD``: approximate minimum degree column ordering\n",
      "        \n",
      "        diag_pivot_thresh : float, optional\n",
      "            Threshold used for a diagonal entry to be an acceptable pivot.\n",
      "            See SuperLU user's guide for details [1]_\n",
      "        relax : int, optional\n",
      "            Expert option for customizing the degree of relaxing supernodes.\n",
      "            See SuperLU user's guide for details [1]_\n",
      "        panel_size : int, optional\n",
      "            Expert option for customizing the panel size.\n",
      "            See SuperLU user's guide for details [1]_\n",
      "        options : dict, optional\n",
      "            Dictionary containing additional expert options to SuperLU.\n",
      "            See SuperLU user guide [1]_ (section 2.4 on the 'Options' argument)\n",
      "            for more details. For example, you can specify\n",
      "            ``options=dict(Equil=False, IterRefine='SINGLE'))``\n",
      "            to turn equilibration off and perform a single iterative refinement.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        invA : scipy.sparse.linalg.SuperLU\n",
      "            Object, which has a ``solve`` method.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        spilu : incomplete LU decomposition\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This function uses the SuperLU library.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] SuperLU http://crd.lbl.gov/~xiaoye/SuperLU/\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import splu\n",
      "        >>> A = csc_matrix([[1., 0., 0.], [5., 0., 2.], [0., -1., 0.]], dtype=float)\n",
      "        >>> B = splu(A)\n",
      "        >>> x = np.array([1., 2., 3.], dtype=float)\n",
      "        >>> B.solve(x)\n",
      "        array([ 1. , -3. , -1.5])\n",
      "        >>> A.dot(B.solve(x))\n",
      "        array([ 1.,  2.,  3.])\n",
      "        >>> B.solve(A.dot(x))\n",
      "        array([ 1.,  2.,  3.])\n",
      "    \n",
      "    spsolve(A, b, permc_spec=None, use_umfpack=True)\n",
      "        Solve the sparse linear system Ax=b, where b may be a vector or a matrix.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : ndarray or sparse matrix\n",
      "            The square matrix A will be converted into CSC or CSR form\n",
      "        b : ndarray or sparse matrix\n",
      "            The matrix or vector representing the right hand side of the equation.\n",
      "            If a vector, b.shape must be (n,) or (n, 1).\n",
      "        permc_spec : str, optional\n",
      "            How to permute the columns of the matrix for sparsity preservation.\n",
      "            (default: 'COLAMD')\n",
      "        \n",
      "            - ``NATURAL``: natural ordering.\n",
      "            - ``MMD_ATA``: minimum degree ordering on the structure of A^T A.\n",
      "            - ``MMD_AT_PLUS_A``: minimum degree ordering on the structure of A^T+A.\n",
      "            - ``COLAMD``: approximate minimum degree column ordering\n",
      "        use_umfpack : bool, optional\n",
      "            if True (default) then use umfpack for the solution.  This is\n",
      "            only referenced if b is a vector and ``scikit-umfpack`` is installed.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray or sparse matrix\n",
      "            the solution of the sparse linear equation.\n",
      "            If b is a vector, then x is a vector of size A.shape[1]\n",
      "            If b is a matrix, then x is a matrix of size (A.shape[1], b.shape[1])\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        For solving the matrix expression AX = B, this solver assumes the resulting\n",
      "        matrix X is sparse, as is often the case for very sparse inputs.  If the\n",
      "        resulting X is dense, the construction of this sparse result will be\n",
      "        relatively expensive.  In that case, consider converting A to a dense\n",
      "        matrix and using scipy.linalg.solve or its variants.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import spsolve\n",
      "        >>> A = csc_matrix([[3, 2, 0], [1, -1, 0], [0, 5, 1]], dtype=float)\n",
      "        >>> B = csc_matrix([[2, 0], [-1, 0], [2, 0]], dtype=float)\n",
      "        >>> x = spsolve(A, B)\n",
      "        >>> np.allclose(A.dot(x).todense(), B.todense())\n",
      "        True\n",
      "    \n",
      "    spsolve_triangular(A, b, lower=True, overwrite_A=False, overwrite_b=False, unit_diagonal=False)\n",
      "        Solve the equation `A x = b` for `x`, assuming A is a triangular matrix.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : (M, M) sparse matrix\n",
      "            A sparse square triangular matrix. Should be in CSR format.\n",
      "        b : (M,) or (M, N) array_like\n",
      "            Right-hand side matrix in `A x = b`\n",
      "        lower : bool, optional\n",
      "            Whether `A` is a lower or upper triangular matrix.\n",
      "            Default is lower triangular matrix.\n",
      "        overwrite_A : bool, optional\n",
      "            Allow changing `A`. The indices of `A` are going to be sorted and zero\n",
      "            entries are going to be removed.\n",
      "            Enabling gives a performance gain. Default is False.\n",
      "        overwrite_b : bool, optional\n",
      "            Allow overwriting data in `b`.\n",
      "            Enabling gives a performance gain. Default is False.\n",
      "            If `overwrite_b` is True, it should be ensured that\n",
      "            `b` has an appropriate dtype to be able to store the result.\n",
      "        unit_diagonal : bool, optional\n",
      "            If True, diagonal elements of `a` are assumed to be 1 and will not be\n",
      "            referenced.\n",
      "        \n",
      "            .. versionadded:: 1.4.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : (M,) or (M, N) ndarray\n",
      "            Solution to the system `A x = b`. Shape of return matches shape of `b`.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If `A` is singular or not triangular.\n",
      "        ValueError\n",
      "            If shape of `A` or shape of `b` do not match the requirements.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        .. versionadded:: 0.19.0\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csr_matrix\n",
      "        >>> from scipy.sparse.linalg import spsolve_triangular\n",
      "        >>> A = csr_matrix([[3, 0, 0], [1, -1, 0], [2, 0, 1]], dtype=float)\n",
      "        >>> B = np.array([[2, 0], [-1, 0], [2, 0]], dtype=float)\n",
      "        >>> x = spsolve_triangular(A, B)\n",
      "        >>> np.allclose(A.dot(x), B)\n",
      "        True\n",
      "    \n",
      "    use_solver(**kwargs)\n",
      "        Select default sparse direct solver to be used.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        useUmfpack : bool, optional\n",
      "            Use UMFPACK over SuperLU. Has effect only if scikits.umfpack is\n",
      "            installed. Default: True\n",
      "        assumeSortedIndices : bool, optional\n",
      "            Allow UMFPACK to skip the step of sorting indices for a CSR/CSC matrix.\n",
      "            Has effect only if useUmfpack is True and scikits.umfpack is installed.\n",
      "            Default: False\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The default sparse solver is umfpack when available\n",
      "        (scikits.umfpack is installed). This can be changed by passing\n",
      "        useUmfpack = False, which then causes the always present SuperLU\n",
      "        based solver to be used.\n",
      "        \n",
      "        Umfpack requires a CSR/CSC matrix to have sorted column/row indices. If\n",
      "        sure that the matrix fulfills this, pass ``assumeSortedIndices=True``\n",
      "        to gain some speed.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['MatrixRankWarning', 'SuperLU', 'factorized', 'linsolve', '...\n",
      "\n",
      "FILE\n",
      "    /home/louis.wicker/miniconda3/envs/main/lib/python3.9/site-packages/scipy/sparse/linalg/dsolve/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dsolve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ad01e59a-dec2-4333-93e7-2419ab07c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import linsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "df65b64b-837d-4bfa-a2b3-039b5c40cac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linsolve.LinAlgError\n",
       "linsolve.MatrixRankWarning\n",
       "linsolve.SparseEfficiencyWarning\n",
       "linsolve.__all__\n",
       "linsolve.__builtins__\n",
       "linsolve.__cached__\n",
       "linsolve.__class__\n",
       "linsolve.__delattr__\n",
       "linsolve.__dict__\n",
       "linsolve.__dir__\n",
       "linsolve.__doc__\n",
       "linsolve.__eq__\n",
       "linsolve.__file__\n",
       "linsolve.__format__\n",
       "linsolve.__ge__\n",
       "linsolve.__getattribute__\n",
       "linsolve.__gt__\n",
       "linsolve.__hash__\n",
       "linsolve.__init__\n",
       "linsolve.__init_subclass__\n",
       "linsolve.__le__\n",
       "linsolve.__loader__\n",
       "linsolve.__lt__\n",
       "linsolve.__name__\n",
       "linsolve.__ne__\n",
       "linsolve.__new__\n",
       "linsolve.__package__\n",
       "linsolve.__reduce__\n",
       "linsolve.__reduce_ex__\n",
       "linsolve.__repr__\n",
       "linsolve.__setattr__\n",
       "linsolve.__sizeof__\n",
       "linsolve.__spec__\n",
       "linsolve.__str__\n",
       "linsolve.__subclasshook__\n",
       "linsolve.asarray\n",
       "linsolve.copy\n",
       "linsolve.csc_matrix\n",
       "linsolve.csr_matrix\n",
       "linsolve.factorized\n",
       "linsolve.is_pydata_spmatrix\n",
       "linsolve.isspmatrix\n",
       "linsolve.isspmatrix_csc\n",
       "linsolve.isspmatrix_csr\n",
       "linsolve.noScikit\n",
       "linsolve.np\n",
       "linsolve.spilu\n",
       "linsolve.splu\n",
       "linsolve.spsolve\n",
       "linsolve.spsolve_triangular\n",
       "linsolve.umfpack\n",
       "linsolve.useUmfpack\n",
       "linsolve.use_solver\n",
       "linsolve.warn"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "linsolve.*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bed06a7f-f08c-425b-b755-2e9f8abc87d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mlinsolve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspsolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermc_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_umfpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Solve the sparse linear system Ax=b, where b may be a vector or a matrix.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "A : ndarray or sparse matrix\n",
       "    The square matrix A will be converted into CSC or CSR form\n",
       "b : ndarray or sparse matrix\n",
       "    The matrix or vector representing the right hand side of the equation.\n",
       "    If a vector, b.shape must be (n,) or (n, 1).\n",
       "permc_spec : str, optional\n",
       "    How to permute the columns of the matrix for sparsity preservation.\n",
       "    (default: 'COLAMD')\n",
       "\n",
       "    - ``NATURAL``: natural ordering.\n",
       "    - ``MMD_ATA``: minimum degree ordering on the structure of A^T A.\n",
       "    - ``MMD_AT_PLUS_A``: minimum degree ordering on the structure of A^T+A.\n",
       "    - ``COLAMD``: approximate minimum degree column ordering\n",
       "use_umfpack : bool, optional\n",
       "    if True (default) then use umfpack for the solution.  This is\n",
       "    only referenced if b is a vector and ``scikit-umfpack`` is installed.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "x : ndarray or sparse matrix\n",
       "    the solution of the sparse linear equation.\n",
       "    If b is a vector, then x is a vector of size A.shape[1]\n",
       "    If b is a matrix, then x is a matrix of size (A.shape[1], b.shape[1])\n",
       "\n",
       "Notes\n",
       "-----\n",
       "For solving the matrix expression AX = B, this solver assumes the resulting\n",
       "matrix X is sparse, as is often the case for very sparse inputs.  If the\n",
       "resulting X is dense, the construction of this sparse result will be\n",
       "relatively expensive.  In that case, consider converting A to a dense\n",
       "matrix and using scipy.linalg.solve or its variants.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from scipy.sparse import csc_matrix\n",
       ">>> from scipy.sparse.linalg import spsolve\n",
       ">>> A = csc_matrix([[3, 2, 0], [1, -1, 0], [0, 5, 1]], dtype=float)\n",
       ">>> B = csc_matrix([[2, 0], [-1, 0], [2, 0]], dtype=float)\n",
       ">>> x = spsolve(A, B)\n",
       ">>> np.allclose(A.dot(x).todense(), B.todense())\n",
       "True\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/main/lib/python3.9/site-packages/scipy/sparse/linalg/dsolve/linsolve.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "linsolve.spsolve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2ec40181-883e-426a-93f8-0340b1fc580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linsolve.use_solver(assumeSortedIndices=True, useUmfpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab9f80-a464-4b71-969d-4a76d8ff79fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
